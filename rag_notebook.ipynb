{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom RAG System (Gemini Flash)\n",
    "\n",
    "## Phase 1: Environment & Project Setup\n",
    "\n",
    "This phase ensures:\n",
    "- Clean project structure\n",
    "- Isolated Python environment\n",
    "- Secure secrets management\n",
    "- Reproducible execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497305d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Scripts\\python.exe\n",
      "Python version: 3.14.2 (tags/v3.14.2:df79316, Dec  5 2025, 17:18:21) [MSC v.1944 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92def2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(\"OS:\", platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8918caa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY loaded: True\n",
      "PINECONE_API_KEY loaded: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"GOOGLE_API_KEY loaded:\", bool(os.getenv(\"GOOGLE_API_KEY\")))\n",
    "print(\"PINECONE_API_KEY loaded:\", bool(os.getenv(\"PINECONE_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a45a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 setup complete and verified.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 1 setup complete and verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2c2dd",
   "metadata": {},
   "source": [
    "# Phase 2: Document Ingestion & Text Extraction\n",
    "\n",
    "This phase:\n",
    "- Loads PDFs from disk\n",
    "- Extracts page-level text\n",
    "- Preserves metadata (source + page)\n",
    "- Performs validation and sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ab3bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64c0b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 PDF files:\n",
      "- lech201.pdf\n",
      "- lech202.pdf\n",
      "- lech203.pdf\n",
      "- lech204.pdf\n",
      "- lech205.pdf\n",
      "- lech2an.pdf\n",
      "- lech2ps.pdf\n"
     ]
    }
   ],
   "source": [
    "PDF_DIR = Path(\"data/pdfs\")\n",
    "assert PDF_DIR.exists(), \"data/pdfs folder does not exist\"\n",
    "\n",
    "pdf_files = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for f in pdf_files:\n",
    "    print(\"-\", f.name)\n",
    "\n",
    "assert len(pdf_files) > 0, \"No PDFs found. Add files to data/pdfs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097521ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading: lech201.pdf\n",
      "  Pages extracted: 34\n",
      "\n",
      "Loading: lech202.pdf\n",
      "  Pages extracted: 34\n",
      "\n",
      "Loading: lech203.pdf\n",
      "  Pages extracted: 32\n",
      "\n",
      "Loading: lech204.pdf\n",
      "  Pages extracted: 22\n",
      "\n",
      "Loading: lech205.pdf\n",
      "  Pages extracted: 22\n",
      "\n",
      "Loading: lech2an.pdf\n",
      "  Pages extracted: 6\n",
      "\n",
      "Loading: lech2ps.pdf\n",
      "  Pages extracted: 14\n",
      "\n",
      "Total pages loaded from all PDFs: 164\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    print(f\"\\nLoading: {pdf_path.name}\")\n",
    "    loader = PyPDFLoader(str(pdf_path))\n",
    "    pages = loader.load()\n",
    "\n",
    "    print(f\"  Pages extracted: {len(pages)}\")\n",
    "    documents.extend(pages)\n",
    "\n",
    "print(f\"\\nTotal pages loaded from all PDFs: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89259c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'producer': 'PDF Printer / www.bullzip.com / FG / Freeware Edition (max 10 users)', 'creator': 'Bullzip PDF Printer (12.2.0.2905)', 'creationdate': '2022-10-14T16:03:07-07:00', 'author': '205DTP3', 'moddate': '2025-04-08T10:06:41+05:30', 'title': 'D:\\\\TEXTBOOKS\\\\RATIONALISED 20222-23\\\\Neha\\\\12086 â€” Chemistry Part_II\\\\1 Source Files\\\\12086 â€” Chemistry Part_II\\\\Unit_6\\\\Unit_6.pmd', 'source': 'data\\\\pdfs\\\\lech201.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "--- Content Preview (first 1000 chars) ---\n",
      "\n",
      "The replacement of hydrogen atom(s) in a n aliphatic\n",
      "or aromatic  hydrocarbon by halogen atom(s) results\n",
      "in the formation of alkyl halide (haloalkane) and aryl\n",
      "halide (haloarene), respectively. Haloalkanes contain\n",
      "halogen atom(s) attached to the sp3 hybridised carbon\n",
      "atom of an alkyl group whereas haloarenes contain\n",
      "halogen atom(s) attached to sp2 hybridised carbon\n",
      "atom(s) of an aryl group. Many halogen containing\n",
      "organic compounds occur in nature and some of\n",
      "these are clinically useful. These classes of compounds\n",
      "find wide applications in industry as well as in day-\n",
      "to-day life. They are used as solvents for relatively\n",
      "non-polar compounds and as starting materials for\n",
      "the synthesis of wide range of organic compounds.\n",
      "Chlorine containing antibiotic, chloramphenicol,\n",
      "produced by microorganisms is very effective for the\n",
      "treatment of typhoid fever . Our body pr oduces iodine\n",
      "containing hormone, thyroxine, the deficiency of which\n",
      "causes a disease called goiter. Synthetic halogen\n",
      "compounds,\n"
     ]
    }
   ],
   "source": [
    "sample = documents[0]\n",
    "print(\"Metadata:\", sample.metadata)\n",
    "print(\"\\n--- Content Preview (first 1000 chars) ---\\n\")\n",
    "print(sample.page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca6799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 164\n",
      "Empty or near-empty pages: 4\n",
      "Indices of empty pages: [148, 149, 150, 155]\n"
     ]
    }
   ],
   "source": [
    "empty_pages = [i for i, d in enumerate(documents) if len(d.page_content.strip()) < 50]\n",
    "\n",
    "print(\"Total pages:\", len(documents))\n",
    "print(\"Empty or near-empty pages:\", len(empty_pages))\n",
    "\n",
    "if len(empty_pages) > 0:\n",
    "    print(\"Indices of empty pages:\", empty_pages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e20d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 270106\n",
      "Average characters per page: 1646\n"
     ]
    }
   ],
   "source": [
    "total_chars = sum(len(d.page_content) for d in documents)\n",
    "avg_chars = total_chars / len(documents)\n",
    "\n",
    "print(\"Total characters:\", total_chars)\n",
    "print(\"Average characters per page:\", int(avg_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c0bbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 complete: Documents ingested and validated.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 2 complete: Documents ingested and validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8ea79",
   "metadata": {},
   "source": [
    "# Phase 3: Text Normalization & Chunking\n",
    "\n",
    "This phase:\n",
    "- Normalizes raw extracted text\n",
    "- Removes formatting noise\n",
    "- Prepares semantically meaningful chunks\n",
    "- Preserves source metadata for traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db8846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ba1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    # Collapse multiple newlines\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "\n",
    "    # Collapse excessive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Strip edges\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f12920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text normalization complete.\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    doc.page_content = normalize_text(doc.page_content)\n",
    "\n",
    "print(\"Text normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd2fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NORMALIZED TEXT SAMPLE ===\n",
      "\n",
      "The replacement of hydrogen atom(s) in a n aliphatic or aromatic hydrocarbon by halogen atom(s) results in the formation of alkyl halide (haloalkane) and aryl halide (haloarene), respectively. Haloalkanes contain halogen atom(s) attached to the sp3 hybridised carbon atom of an alkyl group whereas haloarenes contain halogen atom(s) attached to sp2 hybridised carbon atom(s) of an aryl group. Many halogen containing organic compounds occur in nature and some of these are clinically useful. These classes of compounds find wide applications in industry as well as in day- to-day life. They are used as solvents for relatively non-polar compounds and as starting materials for the synthesis of wide range of organic compounds. Chlorine containing antibiotic, chloramphenicol, produced by microorganisms is very effective for the treatment of typhoid fever . Our body pr oduces iodine containing hormone, thyroxine, the deficiency of which causes a disease called goiter. Synthetic halogen compounds, \n"
     ]
    }
   ],
   "source": [
    "print(\"=== NORMALIZED TEXT SAMPLE ===\\n\")\n",
    "print(documents[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61897a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e513e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 164\n",
      "Total chunks created: 384\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Total pages:\", len(documents))\n",
    "print(\"Total chunks created:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4507e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk metadata: {'producer': 'PDF Printer / www.bullzip.com / FG / Freeware Edition (max 10 users)', 'creator': 'Bullzip PDF Printer (12.2.0.2905)', 'creationdate': '2022-10-14T16:03:07-07:00', 'author': '205DTP3', 'moddate': '2025-04-08T10:06:41+05:30', 'title': 'D:\\\\TEXTBOOKS\\\\RATIONALISED 20222-23\\\\Neha\\\\12086 â€” Chemistry Part_II\\\\1 Source Files\\\\12086 â€” Chemistry Part_II\\\\Unit_6\\\\Unit_6.pmd', 'source': 'data\\\\pdfs\\\\lech201.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "--- Chunk preview ---\n",
      "\n",
      "The replacement of hydrogen atom(s) in a n aliphatic or aromatic hydrocarbon by halogen atom(s) results in the formation of alkyl halide (haloalkane) and aryl halide (haloarene), respectively. Haloalkanes contain halogen atom(s) attached to the sp3 hybridised carbon atom of an alkyl group whereas haloarenes contain halogen atom(s) attached to sp2 hybridised carbon atom(s) of an aryl group. Many halogen containing organic compounds occur in nature and some of these are clinically useful. These classes of compounds find wide applications in industry as well as in day- to-day life. They are used as solvents for relatively non-polar compounds and as starting materials for the synthesis of wide range of organic compounds. Chlorine containing antibiotic, chloramphenicol, produced by microorganisms is very effective for the treatment of typhoid fever . Our body pr oduces iodine containing hormone, thyroxine, the deficiency of which causes a disease called goiter\n"
     ]
    }
   ],
   "source": [
    "sample_chunk = chunks[0]\n",
    "\n",
    "print(\"Chunk metadata:\", sample_chunk.metadata)\n",
    "print(\"\\n--- Chunk preview ---\\n\")\n",
    "print(sample_chunk.page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d4fceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min chunk size: 15\n",
      "Max chunk size: 1000\n",
      "Avg chunk size: 741\n"
     ]
    }
   ],
   "source": [
    "sizes = [len(c.page_content) for c in chunks]\n",
    "\n",
    "print(\"Min chunk size:\", min(sizes))\n",
    "print(\"Max chunk size:\", max(sizes))\n",
    "print(\"Avg chunk size:\", sum(sizes) // len(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b72c3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 complete: Text normalized and chunked successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 3 complete: Text normalized and chunked successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432bb5e",
   "metadata": {},
   "source": [
    "# Phase 4: Embedding Generation (Sentence Transformers)\n",
    "\n",
    "This phase:\n",
    "- Initializes a HuggingFace embedding model\n",
    "- Converts text chunks into vector embeddings\n",
    "- Verifies embedding shape and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa0481b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28cd1337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2cc33735dc4abc80c085a0b8229858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "print(\"Loading embedding model:\", EMBEDDING_MODEL_NAME)\n",
    "embedder = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02dbeb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks to embed: 384\n"
     ]
    }
   ],
   "source": [
    "texts = [chunk.page_content for chunk in chunks]\n",
    "print(\"Total chunks to embed:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6697d3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31812ba1e9ca4e6c9273d7d99a8dde30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated.\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedder.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe0404c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings array shape: (384, 384)\n",
      "Single embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings array shape:\", embeddings.shape)\n",
    "print(\"Single embedding dimension:\", embeddings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0da17eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding (first 10 values):\n",
      "[ 0.00261767 -0.03758737 -0.08557532 -0.03558457  0.12289263  0.07794212\n",
      "  0.02970156  0.0951428   0.06869452 -0.02832721]\n",
      "Vector norm: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample embedding (first 10 values):\")\n",
    "print(embeddings[0][:10])\n",
    "print(\"Vector norm:\", np.linalg.norm(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3903e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding consistency checks passed.\n"
     ]
    }
   ],
   "source": [
    "assert embeddings.shape[0] == len(chunks), \"Mismatch between chunks and embeddings!\"\n",
    "assert embeddings.shape[1] == 384, \"Unexpected embedding dimension!\"\n",
    "\n",
    "print(\"Embedding consistency checks passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd5983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 complete: Embeddings generated and validated.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 4 complete: Embeddings generated and validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45164ce",
   "metadata": {},
   "source": [
    "# Phase 5: Vector Database (Pinecone Serverless)\n",
    "\n",
    "This phase:\n",
    "- Initializes Pinecone Serverless client\n",
    "- Creates a new serverless index (if needed)\n",
    "- Batches and upserts vectors with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48221bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "042290cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone client initialized.\n"
     ]
    }
   ],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "assert PINECONE_API_KEY is not None, \"Missing PINECONE_API_KEY\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"Pinecone client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46db234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing index: notebooklm-rag-antigravity\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"notebooklm-rag-antigravity\"\n",
    "\n",
    "existing_indexes = [i[\"name\"] for i in pc.list_indexes()]\n",
    "\n",
    "if INDEX_NAME not in existing_indexes:\n",
    "    print(\"Creating new serverless index:\", INDEX_NAME)\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=embeddings.shape[1],\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"Using existing index:\", INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bae28fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "394a3af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared vectors: 384\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "\n",
    "for i, (chunk, vector) in enumerate(zip(chunks, embeddings)):\n",
    "    vectors.append({\n",
    "        \"id\": f\"chunk-{i}\",\n",
    "        \"values\": vector.tolist(),\n",
    "        \"metadata\": {\n",
    "            \"source\": chunk.metadata.get(\"source\", \"\"),\n",
    "            \"page\": chunk.metadata.get(\"page\", \"\"),\n",
    "            \"text\": chunk.page_content[:1000]  # metadata size safety\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(\"Prepared vectors:\", len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07f8aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 100 / 384 vectors\n",
      "Uploaded 200 / 384 vectors\n",
      "Uploaded 300 / 384 vectors\n",
      "Uploaded 384 / 384 vectors\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "for i in range(0, len(vectors), BATCH_SIZE):\n",
    "    batch = vectors[i:i+BATCH_SIZE]\n",
    "    index.upsert(vectors=batch)\n",
    "    print(f\"Uploaded {min(i + BATCH_SIZE, len(vectors))} / {len(vectors)} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03553a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index stats: {'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
      "                                    'content-length': '185',\n",
      "                                    'content-type': 'application/json',\n",
      "                                    'date': 'Wed, 28 Jan 2026 09:12:04 GMT',\n",
      "                                    'grpc-status': '0',\n",
      "                                    'server': 'envoy',\n",
      "                                    'x-envoy-upstream-service-time': '42',\n",
      "                                    'x-pinecone-request-id': '2147333110094194392',\n",
      "                                    'x-pinecone-request-latency-ms': '41',\n",
      "                                    'x-pinecone-response-duration-ms': '43'}},\n",
      " 'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'memoryFullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'__default__': {'vector_count': 384}},\n",
      " 'storageFullness': 0.0,\n",
      " 'total_vector_count': 384,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "stats = index.describe_index_stats()\n",
    "print(\"Index stats:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f3cffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 5 complete: Vectors successfully stored in Pinecone Serverless.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 5 complete: Vectors successfully stored in Pinecone Serverless.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868f87e",
   "metadata": {},
   "source": [
    "# Phase 6: Semantic Retrieval Layer\n",
    "\n",
    "This phase:\n",
    "- Encodes user queries\n",
    "- Performs similarity search in Pinecone\n",
    "- Retrieves top-k relevant chunks\n",
    "- Allows inspection of retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecd7610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5336d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_query(query: str) -> np.ndarray:\n",
    "    vec = embedder.encode(\n",
    "        [query],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    return vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "955bdfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(query: str, k: int = 5):\n",
    "    query_vec = embed_query(query)\n",
    "\n",
    "    result = index.query(\n",
    "        vector=query_vec.tolist(),\n",
    "        top_k=k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    return result[\"matches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b17593df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved chunks: 5\n"
     ]
    }
   ],
   "source": [
    "TEST_QUERY = \"What is the main topic discussed in these documents?\"\n",
    "\n",
    "results = retrieve_top_k(TEST_QUERY, k=5)\n",
    "\n",
    "print(\"Retrieved chunks:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59014025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Score: 0.451507598\n",
      "Source: data\\pdfs\\lech2an.pdf\n",
      "Page: 5\n",
      "\n",
      "Text Preview:\n",
      "\n",
      "Notes Reprint 2025-26\n",
      "\n",
      "--- Result 2 ---\n",
      "Score: 0.451507598\n",
      "Source: data\\pdfs\\lech2an.pdf\n",
      "Page: 4\n",
      "\n",
      "Text Preview:\n",
      "\n",
      "Notes Reprint 2025-26\n",
      "\n",
      "--- Result 3 ---\n",
      "Score: 0.398946285\n",
      "Source: data\\pdfs\\lech2ps.pdf\n",
      "Page: 7\n",
      "\n",
      "Text Preview:\n",
      "\n",
      ". A team of experts constituted by the NCERT has developed the manuscript of the book. It gives me great pleasure to acknowledge the valuable contribution of all the members of this team. I also acknowledge the valuable and relentless contribution of the editors in bringing the book to the present shape. I also acknowledge with thanks the dedicated efforts and valuable contribution of Professor Brahm Parkash, who not only coordinated the entire programme but also actively involved in writing and editing of this book. Thanks are also due to the participating teachers and subject experts of the review workshop for their contribution, which has helped us to make the book learner friendly. Also, I thank the technical and administrative staf f of the NCER T for their support in the entire process. The team of this textbook development programme hopes that the book stimulates its readers and makes them feel the excitement and fascination for this subject\n",
      "\n",
      "--- Result 4 ---\n",
      "Score: 0.377543449\n",
      "Source: data\\pdfs\\lech2ps.pdf\n",
      "Page: 3\n",
      "\n",
      "Text Preview:\n",
      "\n",
      "iv Several teachers contributed to the development of this textbook; we are grateful to their principals for making this possible. We are indebted to the institutions and organisations which have generously permitted us to draw upon their resources, material and personnel. As an organisation committed to systemic reform and continuous impr ovement in the quality of its pr oducts, NCER T welcomes comments and suggestions which will enable us to undertake further revision and refinement. Director New Delhi National Council of Educational 20 November 2006 Research and Training Reprint 2025-26\n",
      "\n",
      "--- Result 5 ---\n",
      "Score: 0.367422104\n",
      "Source: data\\pdfs\\lech2ps.pdf\n",
      "Page: 6\n",
      "\n",
      "Text Preview:\n",
      "\n",
      ". Structural formulae of chemical compounds showing functional/coordinating groups in different colours are drawn using electronic system. Each Unit has a good number of examples, as illustrations, with their solutions and some intext questions, the answers of some of which are given at the end of the Unit. The end of Unit exercises are designed to apply important principles and provoke thinking process to solve them. Answers of some of these exercises are given at the end of the book. A variety of materials, e.g., biographical sketches of some scientists, additional information related to a particular topic, etc., is given in boxes with a deep yellow coloured bar. This boxed material with a 'deep yellow bar' is to bring additional life to the topic. However , it is non-evaluative. The structur es of some of the more complex compounds incorporated in the book are for understanding their chemistry\n"
     ]
    }
   ],
   "source": [
    "for i, match in enumerate(results, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(\"Score:\", match[\"score\"])\n",
    "    print(\"Source:\", match[\"metadata\"].get(\"source\"))\n",
    "    print(\"Page:\", match[\"metadata\"].get(\"page\"))\n",
    "    print(\"\\nText Preview:\\n\")\n",
    "    print(match[\"metadata\"].get(\"text\")[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6b1b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval sanity check passed.\n"
     ]
    }
   ],
   "source": [
    "assert len(results) > 0, \"No retrieval results returned!\"\n",
    "print(\"Retrieval sanity check passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0bcc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 6 complete: Semantic retrieval layer operational.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 6 complete: Semantic retrieval layer operational.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df22439",
   "metadata": {},
   "source": [
    "# Phase 7: RAG Answer Generation (Gemini Flash)\n",
    "\n",
    "This phase:\n",
    "- Integrates Gemini Flash as the LLM\n",
    "- Combines semantic retrieval + generation\n",
    "- Uses strict grounding to prevent hallucination\n",
    "- Produces user-facing answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87fc672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Flash initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GCV\\AppData\\Local\\Temp\\ipykernel_22736\\182369644.py:2: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "assert GOOGLE_API_KEY is not None, \"Missing GOOGLE_API_KEY\"\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-flash-latest\")\n",
    "print(\"Gemini Flash initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06e58bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(retrieved_matches, max_chars=6000):\n",
    "    context_blocks = []\n",
    "    total_chars = 0\n",
    "\n",
    "    for match in retrieved_matches:\n",
    "        text = match[\"metadata\"].get(\"text\", \"\")\n",
    "        source = match[\"metadata\"].get(\"source\", \"\")\n",
    "        page = match[\"metadata\"].get(\"page\", \"\")\n",
    "\n",
    "        block = f\"[Source: {source}, Page: {page}]\\n{text}\\n\"\n",
    "        \n",
    "        if total_chars + len(block) > max_chars:\n",
    "            break\n",
    "\n",
    "        context_blocks.append(block)\n",
    "        total_chars += len(block)\n",
    "\n",
    "    return \"\\n---\\n\".join(context_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f844db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_prompt(context: str, question: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You are a factual assistant.\n",
    "\n",
    "Answer the question strictly using ONLY the context below.\n",
    "If the answer is not present in the context, say:\n",
    "\"I don't have enough information in the provided documents.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b0ab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query: str, k: int = 5):\n",
    "    # Step 1: Retrieve relevant chunks\n",
    "    retrieved = retrieve_top_k(query, k=k)\n",
    "\n",
    "    # Step 2: Build context window\n",
    "    context = build_context(retrieved)\n",
    "\n",
    "    # Step 3: Build grounded prompt\n",
    "    prompt = build_rag_prompt(context, query)\n",
    "\n",
    "    # Step 4: Generate answer using Gemini\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"answer\": response.text,\n",
    "        \"context\": context,\n",
    "        \"retrieved\": retrieved\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d106647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " Summarize the main topics discussed in these documents.\n",
      "\n",
      "ANSWER:\n",
      " The documents primarily discuss the development and structure of a book or textbook manuscript, along with acknowledgments and publication details.\n",
      "\n",
      "Key topics include:\n",
      "\n",
      "1.  **Book Development and Structure:** A team of experts constituted by the NCERT developed the book's manuscript. The book's content features structural formulae of chemical compounds showing functional/coordinating groups in different colours, examples with solutions, intext questions, and end of Unit exercises designed to provoke thinking. It also incorporates non-evaluative material, such as biographical sketches of scientists and additional information, given in boxes with a deep yellow coloured bar. The aim is to make the book learner friendly and stimulate readers' interest in the subject.\n",
      "2.  **Acknowledgments:** Valuable contributions were acknowledged from team members, editors, Professor Brahm Parkash (who coordinated the programme and was actively involved in writing and editing), participating teachers, subject experts of the review workshop, technical and administrative staff of the NCERT, teachers, principals, institutions, and organizations.\n",
      "3.  **NCERT's Commitment:** The NCERT is committed to systemic reform and continuous improvement and welcomes comments and suggestions for further revision and refinement.\n",
      "4.  **Publication Details:** A date mentioned is 20 November 2006 (New Delhi), and the text notes the reprint year 2025-26.\n"
     ]
    }
   ],
   "source": [
    "TEST_QUESTION = \"Summarize the main topics discussed in these documents.\"\n",
    "\n",
    "result = rag_answer(TEST_QUESTION, k=5)\n",
    "\n",
    "print(\"QUESTION:\\n\", result[\"query\"])\n",
    "print(\"\\nANSWER:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9367e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONTEXT USED FOR ANSWER ===\n",
      "\n",
      "[Source: data\\pdfs\\lech2ps.pdf, Page: 7]\n",
      ". A team of experts constituted by the NCERT has developed the manuscript of the book. It gives me great pleasure to acknowledge the valuable contribution of all the members of this team. I also acknowledge the valuable and relentless contribution of the editors in bringing the book to the present shape. I also acknowledge with thanks the dedicated efforts and valuable contribution of Professor Brahm Parkash, who not only coordinated the entire programme but also actively involved in writing and editing of this book. Thanks are also due to the participating teachers and subject experts of the review workshop for their contribution, which has helped us to make the book learner friendly. Also, I thank the technical and administrative staf f of the NCER T for their support in the entire process. The team of this textbook development programme hopes that the book stimulates its readers and makes them feel the excitement and fascination for this subject\n",
      "\n",
      "---\n",
      "[Source: data\\pdfs\\lech2ps.pdf, Page: 3]\n",
      "iv Several teachers contributed to the development of this textbook; we are grateful to their principals for making this possible. We are indebted to the institutions and organisations which have generously permitted us to draw upon their resources, material and personnel. As an organisation committed to systemic reform and continuous impr ovement in the quality of its pr oducts, NCER T welcomes comments and suggestions which will enable us to undertake further revision and refinement. Director New Delhi National Council of Educational 20 November 2006 Research and Training Reprint 2025-26\n",
      "\n",
      "---\n",
      "[Source: data\\pdfs\\lech2an.pdf, Page: 4]\n",
      "Notes Reprint 2025-26\n",
      "\n",
      "---\n",
      "[Source: data\\pdfs\\lech2an.pdf, Page: 5]\n",
      "Notes Reprint 2025-26\n",
      "\n",
      "---\n",
      "[Source: data\\pdfs\\lech2ps.pdf, Page: 6]\n",
      ". Structural formulae of chemical compounds showing functional/coordinating groups in different colours are drawn using electronic system. Each Unit has a good number of examples, as illustrations, with their solutions and some intext questions, the answers of some of which are given at the end of the Unit. The end of Unit exercises are designed to apply important principles and provoke thinking process to solve them. Answers of some of these exercises are given at the end of the book. A variety of materials, e.g., biographical sketches of some scientists, additional information related to a particular topic, etc., is given in boxes with a deep yellow coloured bar. This boxed material with a 'deep yellow bar' is to bring additional life to the topic. However , it is non-evaluative. The structur es of some of the more complex compounds incorporated in the book are for understanding their chemistry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== CONTEXT USED FOR ANSWER ===\\n\")\n",
    "print(result[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bfee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Interactive Q&A Mode\n",
      "Type 'exit' to quit\n",
      "\n",
      "\n",
      "âœ… ANSWER:\n",
      "I don't have enough information in the provided documents.\n",
      "\n",
      "\n",
      "âœ… ANSWER:\n",
      "I don't have enough information in the provided documents.\n",
      "\n",
      "\n",
      "âœ… ANSWER:\n",
      "I don't have enough information in the provided documents.\n",
      "\n",
      "\n",
      "âœ… ANSWER:\n",
      "I don't have enough information in the provided documents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ¤– Interactive Q&A Mode\")\n",
    "print(\"Type 'exit' to quit\\n\")\n",
    "\n",
    "while True:\n",
    "    user_question = input(\"\\nâ“ Your question: \")\n",
    "    \n",
    "    if user_question.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    result = rag_answer(user_question, k=5)\n",
    "    print(f\"\\nâœ… ANSWER:\\n{result['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 7 complete: End-to-end RAG system operational with Gemini Flash.\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 7 complete: End-to-end RAG system operational with Gemini Flash.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941afb19",
   "metadata": {},
   "source": [
    "# Phase 8: Evaluation & NotebookLM Comparison\n",
    "\n",
    "This phase compares:\n",
    "- NotebookLM output\n",
    "- Custom RAG (Gemini Flash) output\n",
    "\n",
    "Using:\n",
    "- Same PDFs\n",
    "- Same query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOKLM_ANSWER = \"\"\"\n",
    "PASTE YOUR NOTEBOOKLM ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d24d1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m EVAL_QUESTION = \u001b[33m\"\u001b[39m\u001b[33mSummarize the main contributions and limitations discussed across these documents.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rag_result = \u001b[43mrag_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEVAL_QUESTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m RAG_ANSWER = rag_result[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRAG ANSWER:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mrag_answer\u001b[39m\u001b[34m(query, k)\u001b[39m\n\u001b[32m      9\u001b[39m prompt = build_rag_prompt(context, query)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 4: Generate answer using Gemini\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: query,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: response.text,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: context,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretrieved\u001b[39m\u001b[33m\"\u001b[39m: retrieved\n\u001b[32m     19\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\grpc\\_interceptor.py:276\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\grpc\\_interceptor.py:328\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     81\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\grpc\\_interceptor.py:314\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    305\u001b[39m (\n\u001b[32m    306\u001b[39m     new_method,\n\u001b[32m    307\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m     new_compression,\n\u001b[32m    312\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\grpc\\_channel.py:1177\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1170\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1175\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1176\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GCV\\.gemini\\antigravity\\scratch\\notebooklm-rag-comparison\\rag-venv\\Lib\\site-packages\\grpc\\_channel.py:1150\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1133\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1134\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1135\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1149\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1151\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EVAL_QUESTION = \"Summarize the main contributions and limitations discussed across these documents.\"\n",
    "\n",
    "rag_result = rag_answer(EVAL_QUESTION, k=5)\n",
    "\n",
    "RAG_ANSWER = rag_result[\"answer\"]\n",
    "\n",
    "print(\"RAG ANSWER:\\n\")\n",
    "print(RAG_ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOKLM ANSWER:\\n\")\n",
    "print(NOTEBOOKLM_ANSWER)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CUSTOM RAG ANSWER:\\n\")\n",
    "print(RAG_ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2db037",
   "metadata": {},
   "source": [
    "## Comparison Observations\n",
    "\n",
    "### Similarities\n",
    "- \n",
    "- \n",
    " \n",
    "### Differences\n",
    "- \n",
    "- \n",
    "\n",
    "### Missing Points\n",
    "- \n",
    "\n",
    "### Extra / Hallucinated Points\n",
    "- \n",
    "\n",
    "### Verdict\n",
    "- Parity: High / Medium / Low\n",
    "- Reason: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
